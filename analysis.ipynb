{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from db_utils import RDSDatabaseConnector \n",
    "from transform_data import DataTransform\n",
    "from get_information import DataFrameInfo\n",
    "import missingno as msno\n",
    "from plotter import Plotter\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy import stats\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = RDSDatabaseConnector.yaml_creds_loader()\n",
    "database = RDSDatabaseConnector(credentials)\n",
    "database.save_df_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan = pd.read_csv('loan_payments.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Column Datatypes\n",
    "a lot of these columns are not formatted to the correct dtype which you can see from the loan.info() below. To remedy this I will convert a lot of these columns which can be formatted correctly using my transform_data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransform.convert_columns(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_term_dict = {'36 months' : 36, '60 months' : 60}\n",
    "loan['term'] = loan['term'].replace(convert_term_dict) # replacing string to flaot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_emp_length_dict = {\n",
    "    '< 1 year' : 0,\n",
    "    '1 year' : 1,\n",
    "    '2 years' : 2,\n",
    "    '3 years' : 3,\n",
    "    '4 years' : 4,\n",
    "    '5 years' : 5,\n",
    "    '6 years' : 6,\n",
    "    '7 years' : 7,\n",
    "    '8 years' : 8,\n",
    "    '9 years' : 9,\n",
    "    '10 years' : 10,\n",
    "    '10+ years' : 11\n",
    "}\n",
    "loan['employment_length'] = loan['employment_length'].replace(convert_emp_length_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe information\n",
    "in this segment I will be looking into the dataframe itself and try and generate useful information about the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameInfo.datatypes(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameInfo.statistics(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameInfo.percent_null(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.null_matrix(loan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Columns\n",
    "---\n",
    "### Null values >= 50%\n",
    "All the columns with >= 50% null values will be dropped as they will introduce too much noise which will not help with analysis.\n",
    "These Columns include: **mths_since_last_delinq,** **mths_since_last_record**, **next_payment_date** and **mths_since_last_major_derog**\n",
    "\n",
    "---\n",
    "\n",
    "We can see **Unnamed: 0** column is equal to the id, so we can safely drop this column and just refer to the id.\n",
    "\n",
    "---\n",
    "### Static Value.\n",
    "\n",
    "The policy_code column is just filled with 1, as this column will not contribute to any findings we can safely drop this column.\n",
    "\n",
    "### non important\n",
    "\n",
    "the id and member_id columns are random numbers assigned to the loan/customer, thus they will not be important in our analysis to find insights, these will be dropped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransform.drop_columns(loan, ['mths_since_last_delinq', 'mths_since_last_record', 'next_payment_date', 'mths_since_last_major_derog'])\n",
    "DataTransform.drop_columns(loan, ['Unnamed: 0', 'policy_code'])\n",
    "DataTransform.drop_columns(loan, ['id','member_id'])\n",
    "loan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.null_matrix(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = DataFrameInfo.get_null_greater_than_zero(loan)\n",
    "\n",
    "print(null_values, \"\\n\\n\")\n",
    "print(loan[null_values.index].nunique()) # unique values for columns with null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the \"term\", \"employment_length\", and \"collections_12_mths_ex_med\" are clearly categorical so lets look at their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    loan.term.unique(),\n",
    "    loan.employment_length.unique(),\n",
    "    loan.collections_12_mths_ex_med.unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets take a closer look at the 'term' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameInfo.count_values(loan, 'term')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is more 36 month terms than 60 month terms, however they seem to be relatively close, so as not to introduce any bias, i shall drop any rows with these null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransform.drop_null_rows_from_columns(loan, ['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameInfo.get_null_greater_than_zero(loan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "employment_length contains values for the customer employment length.\n",
    "We should remove any null values for this column as not to introduce any bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransform.drop_null_rows_from_columns(loan,['employment_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last_payment_date, last_credit_pull_date and collections_12_mths_ex_med have very little null values so lets just drop those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransform.drop_null_rows_from_columns(loan,['last_payment_date', 'last_credit_pull_date', 'collections_12_mths_ex_med'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameInfo.get_null_greater_than_zero(loan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Null Values\n",
    "\n",
    "lets take a closer look at the int_rate to possible impute these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know from earlier that inr_rate is not categorical.\n",
    "Plotter.plot_boxplot(loan['int_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_boxplot(loan['funded_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "There are a lot of outliers in the interest rates, we will not get rid of them yet. To remove the null values it would therefore be sensible to impute the median values so the outliers have a lesser effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan['int_rate'].fillna(loan['int_rate'].median(), inplace=True)\n",
    "loan['funded_amount'].fillna(loan['funded_amount'].median(), inplace=True)\n",
    "\n",
    "DataFrameInfo.get_null_greater_than_zero(loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.null_matrix(loan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer have any null values in our DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skewness\n",
    "\n",
    "in this section we will check for skewness and attempt to transform the skewed data inro a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what columns will we transform\n",
    "\n",
    "since total_rec_late_fee, recoveries, delinq_2yrs, out_prncp, our_prncp_inv, collection_recovery_fee, collections_12_mths_ex_med have some inherent bias, we will not transform these columns.\n",
    "\n",
    "term has only 2 values so we dont ahve to worry about that.\n",
    "\n",
    "\n",
    "otherwise any |skewness| > 0.5 will be transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = [\n",
    "    'loan_amount',\n",
    "    'funded_amount',\n",
    "    'funded_amount_inv',\n",
    "    'instalment',\n",
    "    'annual_inc',\n",
    "    'inq_last_6mths',\n",
    "    'open_accounts',\n",
    "    'total_accounts',\n",
    "    'total_payment',\n",
    "    'total_payment_inv',\n",
    "    'total_rec_prncp',\n",
    "    'total_rec_int',\n",
    "    'last_payment_amount',\n",
    "]\n",
    "loan['loan_amount'].hist(bins=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot_annual_inc = qqplot(loan['loan_amount'], line='q', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see a positive skew due to over representation of smaller values and under representation of larger values.\n",
    "\n",
    "lets use a log transform to try normalise the annual income column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean = loan.copy() # creating a copy of our dataframe so we can go back to older data\n",
    "loan_amount_transformed = DataTransform.log_transform(loan_clean, 'loan_amount')\n",
    "loan_amount_transformed.hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_amount_transformed.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to keep |skewness| < 0.5 so lets try a boxcox transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_amount_transformed = DataTransform.boxcox_transform(loan, 'loan_amount', lmbda=0.4) # try a lambda value of 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_amount_transformed.hist(bins=60)\n",
    "loan_amount_transformed.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the boxcox gets us below our 0.5 threshold so we shall keep it like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean['loan_amount'] = loan_amount_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets log transform the rest of the columns to see if it gets below our threshold, otherwise we can try a boxcox transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.remove('loan_amount') # dropping 'loan_amount'\n",
    "\n",
    "for column in transform:\n",
    "    transformed = DataTransform.log_transform(loan, column)\n",
    "    print(f\"{column}: {transformed.skew()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annual_inc, open_accounts and last_payment_amount are within are threshold and can stay with the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean['annual_inc'] = DataTransform.log_transform(loan, 'annual_inc')\n",
    "loan_clean['open_accounts'] = DataTransform.log_transform(loan, 'open_accounts')\n",
    "loan_clean['last_payment_amount'] = DataTransform.log_transform(loan, 'last_payment_amount')\n",
    "\n",
    "loan_clean[transform].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can attempt to do a boxcox transform on the columns, first we'll use a lambda value of 0.3 and see if that gets any columns below our threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.remove('annual_inc')\n",
    "transform.remove('open_accounts')\n",
    "transform.remove('last_payment_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in transform:\n",
    "    transformed = DataTransform.boxcox_transform(loan, column, 0.3)\n",
    "    print(f\"{column}: {transformed.skew()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that brings a lot of columns into our threshold for skewness, so lets update those columns with lambda= 0.3 and look further into the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in transform:\n",
    "    loan_clean[column] = DataTransform.boxcox_transform(loan, column, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean.to_csv('loans_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is roughly in line with what we want to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Outliers\n",
    "\n",
    "in this section we will be removing any outliers that will affect the data, to do this I will first plot some boxplots for each numerical column to see the different outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_columns = [\n",
    "'loan_amount',\n",
    "'funded_amount',\n",
    "'funded_amount_inv',\n",
    "'int_rate',\n",
    "'instalment',\n",
    "'employment_length',\n",
    "'annual_inc',\n",
    "'dti',\n",
    "'inq_last_6mths',\n",
    "'open_accounts',\n",
    "'total_accounts',\n",
    "'total_payment',\n",
    "'total_payment_inv',\n",
    "'total_rec_prncp',\n",
    "'total_rec_int',\n",
    "'last_payment_amount',\n",
    "] # all columns that dont have 0 as upper and lower fence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identifying outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_boxplot(loan_clean[boxplot_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are a lot of outliers here though it seems loan_amount is pretty stable lets replot without loan_amount to see a better picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_columns.remove('loan_amount')\n",
    "Plotter.plot_boxplot(loan_clean[boxplot_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see a lot of outliers here, lets take a closer look at annual_inc and open_accounts, and then identify the outlier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_boxplot(loan_clean[['annual_inc', 'open_accounts']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in boxplot_columns:\n",
    "    print(DataFrameInfo.find_outliers(loan_clean, column))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets proceed to remove these outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in boxplot_columns:\n",
    "    DataTransform.remove_outliers(loan_clean, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the outliers are removed lets replot the box plots to see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_boxplot(loan_clean[boxplot_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_boxplot(loan_clean[['annual_inc','open_accounts']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the outliers are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this section we will calculate the correlation matrix and proceed to find any colinear variables and drop any which is too high, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = loan.corr(numeric_only=True)\n",
    "\n",
    "Plotter.correlation_matrix(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we see from the matrix:\n",
    "- out_prncp and out_prncp_inv are VERY similar with a correlation of 1 (we are going to drop one of these)\n",
    "- there is multicollinearity between loan_amount, funded_amount and funded_amount_inv, it will be safe to drop one or 2 of these variables\n",
    "- there is multicollinearity between total_payment, total_payment_inv and total_rec_prncp, it will be safe to drop one or 2 of these variables\n",
    "- there is strong co linearity between recoveries and collection_recovery_fee, we can drop one of these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based off the analysis of the matrix I will be dropping the following columns:\n",
    "- out_prncp_inv\n",
    "- funded_amount and funded_amount_inv\n",
    "- total_payment_inv and total_rec_prncp\n",
    "- collection_recovery_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.drop(columns=['out_prncp_inv','funded_amount', 'funded_amount_inv', 'total_payment_inv', 'total_rec_prncp', 'collection_recovery_fee'], inplace=True)\n",
    "loan_clean.drop(columns=['out_prncp_inv','funded_amount', 'funded_amount_inv', 'total_payment_inv', 'total_rec_prncp', 'collection_recovery_fee'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = loan.corr(numeric_only=True)\n",
    "\n",
    "Plotter.correlation_matrix(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a lot of the colinearity has been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current state of loans:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean['percentage_recovered'] = loan['total_payment']/loan['loan_amount']\n",
    "loan_clean['recovered'] = loan_clean['percentage_recovered'].map(lambda x: True if x >= 1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_hist(loan_clean, 'percentage_recovered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loan_clean['recovered'].sum()/len(loan_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55% of loans are paid off, leaving 45% unpaid, now lets take a look 6 months in the future and see how many of those below 100%(of the loan paid off) will be able to pay it off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_unpaid = loan[loan['total_payment'] < loan['loan_amount']] # select only unpaid loan records\n",
    "loan_unpaid['total_payment'] = loan_unpaid['total_payment'] + 6*loan_unpaid['instalment'] # 6 months of payments\n",
    "loan_unpaid['percentage_recovered'] = loan_unpaid['total_payment'] / loan_unpaid['loan_amount']\n",
    "Plotter.plot_hist(loan_unpaid, 'percentage_recovered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_unpaid['recovered'] = loan_unpaid['percentage_recovered'].map(lambda x: True if x >= 1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(loan_unpaid['recovered'].sum()/len(loan_unpaid) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36.6% will repay their loans within 6 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculated Loss\n",
    "in this section we will calculate loss of loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean.groupby(['loan_status'], observed=False).loan_amount.count() # counts loan_status' in loan_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity those assigned as \"Does not meet the credit policy will be assigned to Charged off or Fully paid respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_loan_status_dict = {\n",
    "    'Does not meet the credit policy. Status:Charged Off' : 'Charged Off',\n",
    "    'Does not meet the credit policy. Status:Fully Paid' : 'Fully Paid'\n",
    "}\n",
    "\n",
    "loan['loan_status'] = loan['loan_status'].replace(convert_loan_status_dict) # main df\n",
    "\n",
    "loan_clean['loan_status'] = loan_clean['loan_status'].replace(convert_loan_status_dict) # cleaned df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean.groupby(['loan_status'], observed=False).loan_amount.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean.groupby(['loan_status'], observed=False).loan_amount.count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(loan_clean[loan_clean['loan_status'] == 'Charged Off']['loan_status'].count() / len(loan_clean) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approximately 10% of loans are charged off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean['total_revenue'] = loan['loan_amount'] * (1+loan['int_rate']/100)**(loan['term']/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean['total_revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_clean[loan_clean['loan_status'] == 'Charged Off']['total_revenue'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the company has lost 110 154 776.78  in revenue from charged off loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
